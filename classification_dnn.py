# -*- coding: utf-8 -*-
"""Classification_DNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QIydzAnbbSGdFLRvyRvE_pCHEeTpY_dX
"""

from google.colab import drive
drive.mount('/content/drive', force_remount= True)

!pip install super-gradients
!pip install torchinfo

import os
import random
import numpy as np
from PIL import Image
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
from tqdm import tqdm
import glob
import super_gradients as sg
from super_gradients.training import models
from torchinfo import summary
from IPython.display import clear_output
from super_gradients.training import dataloaders
from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train, coco_detection_yolo_format_val

import torch
device = 'cuda' if torch.cuda.is_available() else "cpu"
print(device)

"""# Small Training Fine Tuning

Let's first create some dataloaders object in order to use as input to out model. This already applies the transformations necessary.
"""

dataset_params = {
    'data_dir':'/content/drive/MyDrive/Final_Project_DNN',
    'train_images_dir':'train/images_resized',
    'train_labels_dir':'train/labels',
    'small_train_images_dir': 'small_train_set/images_resized',
    'small_train_labels_dir': 'small_train_set/labels',
    'val_images_dir':'validation/images_resized',
    'val_labels_dir':'validation/labels',
    'test_images_dir':'test/images_resized',
    'test_labels_dir':'test/labels',
    'classes': ['Smoke', 'Fire']
}

""" The following may take a while to run. Even with GPU's."""

# Training Loader

train_data = coco_detection_yolo_format_train(
    dataset_params={
        'data_dir': dataset_params['data_dir'],
        'images_dir': dataset_params['train_images_dir'],
        'labels_dir': dataset_params['train_labels_dir'],
        'classes': dataset_params['classes']
    },
    dataloader_params={
        'batch_size':16,
        'num_workers':2
    }
)

# Small training_set loader

small_train_data = coco_detection_yolo_format_train(
    dataset_params={
        'data_dir': dataset_params['data_dir'],
        'images_dir': dataset_params['small_train_images_dir'],
        'labels_dir': dataset_params['small_train_labels_dir'],
        'classes': dataset_params['classes']
    },
    dataloader_params={
        'batch_size':16,
        'num_workers':2
    }
)

# Validation Loader

val_data = coco_detection_yolo_format_val(
    dataset_params={
        'data_dir': dataset_params['data_dir'],
        'images_dir': dataset_params['val_images_dir'],
        'labels_dir': dataset_params['val_labels_dir'],
        'classes': dataset_params['classes']
    },
    dataloader_params={
        'batch_size':16,
        'num_workers':2
    }
)

# Test Loader

test_data = coco_detection_yolo_format_val(
    dataset_params={
        'data_dir': dataset_params['data_dir'],
        'images_dir': dataset_params['test_images_dir'],
        'labels_dir': dataset_params['test_labels_dir'],
        'classes': dataset_params['classes']
    },
    dataloader_params={
        'batch_size':16,
        'num_workers':2
    }
)

clear_output()

"""Let's explore the data set in use and have an idea of the transformations applied to our transformation data. Transformations applied:

> - DetectionPaddedRescale: Padds images that are smaller than the pretended input size.
> - DetectionMosaic: Mixes up to 4 images and respective labels in one.
> - DetectionRandomAffine: Applies random rottation and or tranlsation to images.
> - DetectionMixup: Blends pairs of samples and their labels and bounding boxes in order to create new, artificial, data.
> - DetectionHSV: Instead of representing the image in RGB it represents the image in HSV. the advantage is that seperates the hue from the saturation.
> - DetectionTargetsFormatTransform: Resizes images from their input shape into an output shape.  
> - DetectionHorizontalFlip: Flips the image by the y-axis.

To edit the transformations applied we can use operations such as we were working with a dictionary. The trasnformations can also be defined while creating the dataset dictionary but it seems to not be as efficient.
"""

# Transformations applied to the training data
train_data.dataset.transforms

"""Example of images with data augmentation in training set."""

train_data.dataset.plot()

"""## Model Training

The function below is to extract the metrics from the experiment logs file the model creates.
"""

import re
import matplotlib.pyplot as plt

def extract_metrics(file_path):
    # Regular expression pattern to match metrics
    pattern = r"(\w+/\w+|\w+@\d\.\d\d):\s+([\d\.e\-]+)"

    # Dictionary to store metrics
    metrics = {}

    # Read file and process each line
    with open(file_path, 'r') as file:
        for line in file:
            # Find all metric-value pairs in the line
            matches = re.findall(pattern, line)

            # Process each match
            for metric, value in matches:
                # Convert value to float
                value = float(value)

                # Add value to the corresponding metric list in the dictionary
                if metric not in metrics:
                    metrics[metric] = []
                metrics[metric].append(value)

    return metrics

"""### Baseline

Initializing the trainer and the model.
"""

from super_gradients.training import Trainer

# checkpoint to save the model and the experiment name
CHECKPOINT_DIR = '/content/drive/MyDrive/Model_checkpoints/Large model/baseline_yolo_nas_checkpoints'
trainer = Trainer(experiment_name = 'baseline_yolo_nas_run', ckpt_root_dir = CHECKPOINT_DIR)

from super_gradients.training import models

model = models.get('yolo_nas_l',
                   num_classes=len(dataset_params['classes']),
                   pretrained_weights="coco"
                   ).to(device)

type(model.to(device))

"""Setting the hyper-parameters and evaluation metrics used."""

from super_gradients.training.losses import PPYoloELoss
from super_gradients.training.metrics import DetectionMetrics_050
from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback

train_params = {
    # ENABLING SILENT MODE
    'silent_mode': True,
    "average_best_models":True,
    "lr_warmup_epochs": 0,
    "initial_lr": 3e-4,
    "lr_mode": "cosine",
    "cosine_final_lr_ratio": 0,
    "optimizer": "Adam",
    "zero_weight_decay_on_bias_and_bn": True,
    # ONLY TRAINING FOR 10 EPOCHS FOR THIS EXAMPLE NOTEBOOK
    "max_epochs": 50,
    "mixed_precision": True,
    "loss": PPYoloELoss(
        use_static_assigner=False,
        # NOTE: num_classes needs to be defined here
        num_classes=len(dataset_params['classes']),
        reg_max=16
    ),
    "valid_metrics_list": [
        DetectionMetrics_050(
            score_thres=0.1,
            top_k_predictions=300,
            num_cls=len(dataset_params['classes']),
            normalize_targets=True,
            post_prediction_callback=PPYoloEPostPredictionCallback(
                score_threshold=0.01,
                nms_top_k=1000,
                max_predictions=300,
                nms_threshold=0.7
            )
        )
    ],
    "metric_to_watch": 'mAP@0.50'
}

"""Training the model"""

trainer.train(model=model,
              training_params=train_params,
              train_loader=train_data,
              valid_loader=val_data)

metrics.pop('LR/Param_group_0')
metrics.pop('LR/Param_group_1')
metrics.keys()

# File path with the experiment logs
file_path = '/content/drive/MyDrive/Model_checkpoints/Large model/yolo_nas_checkpoints/baseline_yolo_nas_run/experiment_logs_Nov21_21_39_44.txt'
metrics = extract_metrics(file_path)
# Identifying matching metrics for train and valid
pairs = []
# Additional metrics that do not have a corresponding training metric
additional_metrics = []

for key in metrics:
    if key.startswith('Train_'):
        valid_key = key.replace('Train_', 'Valid_')
        if valid_key in metrics:
            pairs.append((key, valid_key))
    elif key.endswith('@0.50'):
      additional_metrics.append(key)


# Determine the grid size for a 2x4 layout
n_cols = 2
n_rows = 4

# Plotting in a 2x4 grid format
fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(8, 13))
axes = axes.flatten()

# Plot the paired metrics
for i, (train_key, valid_key) in enumerate(pairs):
    epochs = range(len(metrics[train_key]))
    axes[i].plot(epochs, metrics[train_key], label=f"Train_{train_key.split('/')[1]}")
    axes[i].plot(epochs, metrics[valid_key], label=f"Valid_{valid_key.split('/')[1]}")
    axes[i].set_title(train_key.split('/')[1])
    axes[i].set_xlabel('Epoch')
    axes[i].set_ylabel('Value')
    axes[i].legend()

# Plot the additional validation metrics
for j, metric in enumerate(additional_metrics, start=len(pairs)):
    epochs = range(len(metrics[metric]))
    axes[j].plot(epochs, metrics[metric], label=metric)
    axes[j].set_title(metric.split('@')[0])
    axes[j].set_xlabel('Epoch')
    axes[j].set_ylabel('Value')
    axes[j].legend()

# Hide any unused subplots
for k in range(j+1, len(axes)):
    axes[k].axis('off')

plt.tight_layout()
plt.show()

"""### Hyper Parameter tuning

Let's set the model in the same way as for the baseline but using a smaller training set.
"""

from super_gradients.training import Trainer

CHECKPOINT_DIR = '/content/drive/MyDrive/Model_checkpoints/Small model/yolo_nas_checkpoints'

trainer = Trainer(experiment_name = 'hyperparameter_tuning_yolo_nas_run_4', ckpt_root_dir = CHECKPOINT_DIR)

from super_gradients.training import models
model = models.get('yolo_nas_l',
                   num_classes=len(dataset_params['classes']),
                   pretrained_weights="coco"
                   ).to(device)

"""> + Baseline: `mAP@0.5: 0.622` | `Precision@0.50: 0.033` | `Recall@0.50: 0.943`

Below it was performed some trial runs in order to compare models with different hyper parameters. Due to high running times a smaller training set was used and therefore the results should be slightly worse than the baseline. The goal is to get the best hyper parameters possible to then apply them in the model with all the data.

> + Run 1: cosine_final_lr_ratio = 0.1 || Validation metrics: `mAP@0.5: 0.0.488` | `Precision@0.50: 0.027` | `Recall@0.50: 0. 0.914`
> + Run 2: cosine_final_lr_ratio = 0.1 | "optimizer_params": {"weight_decay": 0.0001} || Validation metrics: `mAP@0.5: 0.454` | `Precision@0.50: 0.027` | `Recall@0.50: 0.903`

> + Run 3: cosine_final_lr_ratio = 0.1 + "optimizer_params": {"weight_decay": 0.0001} + 4 warmup epchs with a lr of 3e-6|| Validation metrics: `mAP@0.5: 0.547` | `Precision@0.50: 0.0326` | `Recall@0.50: 0.922` -> Big improvement but noisy

> + Run 4: cosine_final_lr_ratio = 0.1 + "optimizer_params": {"weight_decay": 0.0001} + 4 warmup epchs with a lr of 3e-6 + Exponential moving average (decay = 0.9) || Validation metrics: `mAP@0.5: 0.541` | `Precision@0.50: 0.039` | `Recall@0.50: 0.925` -> Converges with less noise

"""

from super_gradients.training.losses import PPYoloELoss
from super_gradients.training.metrics import DetectionMetrics_050
from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback


train_params = {
    # ENABLING SILENT MODE
    'silent_mode': True,
    "average_best_models":True,
    "warmup_mode": "linear_epoch_step",
    "warmup_initial_lr": 3e-6,
    "lr_warmup_epochs": 4,
    "initial_lr": 3e-4,
    "lr_mode": "cosine",
    "cosine_final_lr_ratio": 0.1,
    "optimizer": "Adam",
    "optimizer_params": {"weight_decay": 0.0001},
    "zero_weight_decay_on_bias_and_bn": True,
    "ema": True,
    "ema_params": {"decay": 0.9, "decay_type": "threshold"},
    "max_epochs": 20,
    "mixed_precision": True,
    "loss": PPYoloELoss(
        use_static_assigner=False,

        num_classes=len(dataset_params['classes']),
        reg_max=16
    ),
    "valid_metrics_list": [
        DetectionMetrics_050(
            score_thres=0.1,
            top_k_predictions=300,

            num_cls=len(dataset_params['classes']),
            normalize_targets=True,
            post_prediction_callback=PPYoloEPostPredictionCallback(
                score_threshold=0.01,
                nms_top_k=1000,
                max_predictions=300,
                nms_threshold=0.7
            )
        )
    ],
    "metric_to_watch": 'mAP@0.50'
}

trainer.train(model=model,
              training_params=train_params,
              train_loader=small_train_data,
              valid_loader=val_data)

"""### Best Model: Full Data"""

And finally repeat the process for the final model with the full data and the tuned hyper parameters.

CHECKPOINT_DIR = '/content/drive/MyDrive/Model_checkpoints/Large model/final_model_yolo_nas'

trainer = Trainer(experiment_name = 'yolo_nas_final_run', ckpt_root_dir = CHECKPOINT_DIR)

model = models.get('yolo_nas_l',
                   num_classes=len(dataset_params['classes']),
                   pretrained_weights="coco"
                   ).to(device)

train_params = {
    # ENABLING SILENT MODE
    'silent_mode': True,
    "average_best_models":True,
    "warmup_mode": "linear_epoch_step",
    "warmup_initial_lr": 3e-6,
    "lr_warmup_epochs": 4,
    "initial_lr": 3e-4,
    "lr_mode": "cosine",
    "cosine_final_lr_ratio": 0.1,
    "optimizer": "Adam",
    "optimizer_params": {"weight_decay": 1e-4},
    "zero_weight_decay_on_bias_and_bn": True,
    "ema": True,
    "ema_params": {"decay": 0.9, "decay_type": "threshold"},
    "max_epochs": 50,
    "mixed_precision": True,
    "loss": PPYoloELoss(
        use_static_assigner=False,
        # NOTE: num_classes needs to be defined here
        num_classes=len(dataset_params['classes']),
        reg_max=16
    ),
    "valid_metrics_list": [
        DetectionMetrics_050(
            score_thres=0.1,
            top_k_predictions=300,
            # NOTE: num_classes needs to be defined here
            num_cls=len(dataset_params['classes']),
            normalize_targets=True,
            post_prediction_callback=PPYoloEPostPredictionCallback(
                score_threshold=0.01,
                nms_top_k=1000,
                max_predictions=300,
                nms_threshold=0.7
            )
        )
    ],
    "metric_to_watch": 'mAP@0.50'
}

trainer.train(model=model,
              training_params=train_params,
              train_loader=train_data,
              valid_loader=val_data)

file_path = '/content/drive/MyDrive/Model_checkpoints/Large model/final_model_yolo_nas/yolo_nas_final_run/RUN_20231122_175549_182853/experiment_logs_Nov22_17_55_49.txt'
metrics = extract_metrics(file_path)

# Identifying matching metrics for train and valid
pairs = []
# Additional metrics that do not have a corresponding training metric
additional_metrics = []

for key in metrics:

    if key.startswith('Train_'):
        valid_key = key.replace('Train_', 'Valid_')
        if valid_key in metrics:
            pairs.append((key, valid_key))
    elif key.endswith('@0.50'):
      additional_metrics.append(key)


# Determine the grid size for a 2x4 layout
n_cols = 2
n_rows = 4

# Plotting in a 2x4 grid format
fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(8, 13))
axes = axes.flatten()

# Plot the paired metrics
for i, (train_key, valid_key) in enumerate(pairs):
    epochs = range(len(metrics[train_key]))
    axes[i].plot(epochs, metrics[train_key], label=f"Train_{train_key.split('/')[1]}")
    axes[i].plot(epochs, metrics[valid_key], label=f"Valid_{valid_key.split('/')[1]}")
    axes[i].set_title(train_key.split('/')[1])
    axes[i].set_xlabel('Epoch')
    axes[i].set_ylabel('Value')
    axes[i].legend()

# Plot the additional validation metrics
for j, metric in enumerate(additional_metrics, start=len(pairs)):
    epochs = range(len(metrics[metric]))
    axes[j].plot(epochs, metrics[metric], label=metric)
    axes[j].set_title(metric.split('@')[0])
    axes[j].set_xlabel('Epoch')
    axes[j].set_ylabel('Value')
    axes[j].legend()

# Hide any unused subplots
for k in range(j+1, len(axes)):
    axes[k].axis('off')

plt.tight_layout()
plt.show()

"""### To reset GPU

It was needed to define a way of reseting the gpu because the GPU was going down after multiple runs to fine the hyper parameters.
"""

from numba import cuda
device = cuda.get_current_device()
device.reset()
device

"""## Model Evaluation

Getting the mest model out of the checkpoints saved.
"""

best_model = models.get('yolo_nas_l',
                        num_classes=2,
                        checkpoint_path="/content/drive/MyDrive/Model_checkpoints/Large model/final_model_yolo_nas/yolo_nas_final_run/RUN_20231122_175549_182853/average_model.pth")

"""Testing the model in our test data."""

trainer.test(model=best_model,
            test_loader=test_data,
            test_metrics_list=DetectionMetrics_050(score_thres=0.1,
                                                   top_k_predictions=300,
                                                   num_cls=len(dataset_params['classes']),
                                                   normalize_targets=True,
                                                   post_prediction_callback=PPYoloEPostPredictionCallback(score_threshold=0.01,
                                                                                                          nms_top_k=1000,
                                                                                                          max_predictions=300,
                                                                                                          nms_threshold=0.7)))

"""### Prediction Examples

Below follows the code used to obtain some examples of predictions using images in the test set.
"""

samples
print(samples)
smoke = ['AoF07116.jpg',
          'AoF08107.jpg',
         '']

good = ['AoF07116.jpg', 'WEB10530.jpg', 'WEB11687.jpg', 'WEB10878.jpg', 'WEB11788.jpg', 'WEB10846.jpg', 'WEB10454.jpg', 'AoF07020.jpg', 'PublicDataset01169.jpg', 'WEB11094.jpg', 'WEB10857.jpg']
bad = ["WEB09509.jpg", 'WEB10575.jpg', 'WEB10627.jpg', 'PublicDataset01100.jpg']

image = cv2.imread("/content/drive/MyDrive/Final_Project_DNN/test/images_resized/WEB10575.jpg")
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
best_model.predict(image)

import random
import cv2

rand_images = random.sample(os.listdir("/content/drive/MyDrive/Final_Project_DNN/test/images_resized"), 9)
samples = []
for image_id in good:
  print(image_id)
  samples.append(image_id)
  image_path = os.path.join("/content/drive/MyDrive/Final_Project_DNN/test/images_resized", image_id)
  image = cv2.imread(image_path)
  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  best_model.predict(image).show()
  # print(predict)
  # break

"""# Video Prediction

Below we access the youtube api in order to obtain a video found online that consists on a news about a fire happening somewhere randomly. The prediction is actually quite good given the format of the video wasn't adjusted to fit the same size used to train the model.
"""

# Define the URL of the YouTube video

video_id = 'Sqj2bm1VwF0'
video_url = f'https://www.youtube.com/watch?v={video_id}'

# Download the video in mp4 format
!pip install -U "git+https://github.com/ytdl-org/youtube-dl.git"
!python -m youtube_dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' "$video_url"

# Print a success message
print('Video downloaded successfully')

input_video_path = f"/content/EXTREME SPORTS X DIVERSE-{video_id}.mp4"
output_video_path = "detections.mp4"

# Download the video in mp4 format
!pip install -U "git+https://github.com/ytdl-org/youtube-dl.git"
!python -m youtube_dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' "$video_url"

# Print a success message
print('Video downloaded successfully')

input_video_path = f"/content/Caught on camera - Fort McMurray fire erupts behind Global News reporter-Sqj2bm1VwF0.mp4"
output_video_path = "detections.mp4"

best_model.to(device).predict(input_video_path).save(output_video_path)